# Topology Aware Routing

## Описание.
Изучение работы Topology Aware Routing в кластере k8s.
https://kubernetes.io/docs/concepts/services-networking/topology-aware-routing/
Помним, что хостов, для корректной работы TAR, должно быть не менее 3 в каждой зоне. Итого для YC не менее 9 нод в кластере.
В примере у меня кластер с 3 нод группами в каждой из зон. И с 4 нодами в каждой группе.

## Подготовка!

### Создадим Deployment с подами на каждом хосте.
На примере этого деплоймента и будем проверять работу TAR.
```
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cam-tar-test
  namespace: default
  labels:
    app: tar
    environment: test
  annotations:
    author: cameda
spec:
  replicas: 12
  selector:
    matchLabels:
      app: cam-tar
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: cam-tar
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: Exists
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: cam-tar
        image: nginx:alpine
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 30m
            memory: 20Mi
          limits:
            memory: 30Mi
      restartPolicy: Always
      hostname: nginx
      nodeSelector:
        kubernetes.io/os: linux
---
apiVersion: v1
kind: Service
metadata:
  namespace: default
  name: svc-tar
  labels:
    environment: test
  annotations:
    service.kubernetes.io/topology-mode: Auto
    author: cameda
spec:
  type: ClusterIP
  selector:
    app: cam-tar
  ports:
  - name: http
    protocol: TCP
    port: 80
EOF
```

### Создадим Deployment с тремя подами в каждой зоне.
С подов этого деплоймента будем обращаться к сервису, который смотрит за подами первого деплоймента.
```
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cam-test-network
  namespace: default
  labels:
    net: net-test
  annotations:
    author: cameda
spec:
  replicas: 3
  selector:
    matchLabels:
      net: cam-test-network
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        net: cam-test-network
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: net
                operator: In
                values:
                - cam-test-network
            topologyKey: topology.kubernetes.io/zone
      containers:
      - name: cam-test-network
        image: amouat/network-utils
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
          limits:
            memory: 100Mi
        command: ["sh", "-c"]
        args: ["sleep 3650d"]
      restartPolicy: Always
      hostname: net
      nodeSelector:
        kubernetes.io/os: linux
EOF
```

### Информация о сервисе.
```
kubectl get svc
NAME                   TYPE           CLUSTER-IP    EXTERNAL-IP      PORT(S)        AGE
kubernetes             ClusterIP      10.6.0.1      <none>           443/TCP        15d
svc-tar                ClusterIP      10.6.147.60   <none>           80/TCP         16m
```

### Три пода из разных зон. С них будем пинговать сервис.
```
kubectl get po -owide
NAME                                READY   STATUS    RESTARTS   AGE     IP            NODE                        NOMINATED NODE   READINESS GATES
cam-test-network-64fdbb4dd8-5zfzs   1/1     Running   0          3m53s   10.5.10.129   cl1bkptetefepgkuttfc-icuj   <none>           <none>
cam-test-network-64fdbb4dd8-798n7   1/1     Running   0          4m4s    10.5.12.231   cl1rv1j4fucfrh1ahavn-otot   <none>           <none>
cam-test-network-64fdbb4dd8-xk9nt   1/1     Running   0          4m4s    10.5.6.43     cl16tpph013gjcebf59k-ynis   <none>           <none>
```

### Поды из первого деплоймента по зонам.
* Зона а.
```
kubectl get po -owide
NAME                                READY   STATUS    RESTARTS   AGE     IP            NODE                        NOMINATED NODE   READINESS GATES
cam-deploy-nginx-7cf558985c-6npdc   1/1     Running   0          43h     10.5.13.79    cl1rv1j4fucfrh1ahavn-ujin   <none>           <none>
cam-deploy-nginx-7cf558985c-75pps   1/1     Running   0          43h     10.5.11.183   cl1rv1j4fucfrh1ahavn-oqej   <none>           <none>
cam-deploy-nginx-7cf558985c-dshrt   1/1     Running   0          43h     10.5.15.144   cl1rv1j4fucfrh1ahavn-ymyq   <none>           <none>
cam-deploy-nginx-7cf558985c-kqhsl   1/1     Running   0          43h     10.5.12.222   cl1rv1j4fucfrh1ahavn-otot   <none>           <none>
```

* Зона b.
```
kubectl get po -owide
NAME                                READY   STATUS    RESTARTS   AGE     IP            NODE                        NOMINATED NODE   READINESS GATES
cam-deploy-nginx-7cf558985c-4w78q   1/1     Running   0          43h     10.5.6.22     cl16tpph013gjcebf59k-ynis   <none>           <none>
cam-deploy-nginx-7cf558985c-6n7f6   1/1     Running   0          43h     10.5.1.76     cl16tpph013gjcebf59k-okik   <none>           <none>
cam-deploy-nginx-7cf558985c-shr67   1/1     Running   0          43h     10.5.0.59     cl16tpph013gjcebf59k-alir   <none>           <none>
cam-deploy-nginx-7cf558985c-x99lq   1/1     Running   0          43h     10.5.8.109    cl16tpph013gjcebf59k-ywir   <none>           <none>
```

* Зона d.
```
kubectl get po -owide
NAME                                READY   STATUS    RESTARTS   AGE     IP            NODE                        NOMINATED NODE   READINESS GATES
cam-deploy-nginx-7cf558985c-95d4r   1/1     Running   0          43h     10.5.4.103    cl1bkptetefepgkuttfc-yrar   <none>           <none>
cam-deploy-nginx-7cf558985c-ntq2q   1/1     Running   0          43h     10.5.10.229   cl1bkptetefepgkuttfc-icuj   <none>           <none>
cam-deploy-nginx-7cf558985c-w4q4c   1/1     Running   0          43h     10.5.5.87     cl1bkptetefepgkuttfc-iriz   <none>           <none>
cam-deploy-nginx-7cf558985c-zx9rr   1/1     Running   0          43h     10.5.9.28     cl1bkptetefepgkuttfc-iriw   <none>           <none>
```

## Поехали!
* Убедимся что при пинге сервиса, ответы приходят от подов из этой же зоны.

kubectl exec -ti cam-test-network-64fdbb4dd8-798n7 -- /bin/bash
ping 10.6.147.60
